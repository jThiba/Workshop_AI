{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ca2ca3-e931-43f0-aa36-fe9266c3ebd8",
   "metadata": {},
   "source": [
    "# POC - AI Pool 2023 - Day 01 - Data Science\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### Data Science & Data scientist\n",
    "\n",
    "Before going further in this subject, let's start by a short definition of what Data Science is : Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data and apply knowledge and actionable insights from data across a broad range of application domains.\n",
    "\n",
    "A Data Scientist is often seen as a handyman from fetching the data to putting a machine learning model in production.\n",
    "In reality, each part related to AI and Data as its own job : The Data Miner fetches the data, the machine learning engineer builds machine learning models and the MLOps deploys those models.\n",
    "\n",
    "Another way to see the Data scientist (which I prefer) is as the one who knows how to handle all works related to data : Data mining, Data exploration, interpretation of the data, its visualization and its processing.\n",
    "\n",
    "We will not go any further into details of each job in AI but if you want to know more I advise you to read [this great book](https://huyenchip.com/ml-interviews-book/contents/chapter-1.-ml-jobs.html) written by _Chip Huyen_ who explains each job in every part of AI.\n",
    "\n",
    "#### What you will see in this subject\n",
    "\n",
    "In this subject you will discover a few bases of Data Science : How to manipulate data, explore it, visualise it and interpret it.\\\n",
    "Eventually, you will learn how to use a machine learning model using the `sklearn` library.\n",
    "\n",
    "If you have any questions, don't hesitate to ask other candidates or one of the supervisors.\\\n",
    "Good luck and have fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a46f5e-6a23-4ee4-a5e1-946e04e789f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8862bba-3d11-452e-978c-1a1b83b9408d",
   "metadata": {},
   "source": [
    "## I - Data Exploration\n",
    "\n",
    "Before manipulating our data or even interpreting it we need to explore it, to know what type of data do we have and what does it mean.\\\n",
    "So let's start by exploring our data using the `pandas` and `searborn` libraries.\n",
    "\n",
    "### I-I Reading a csv\n",
    "\n",
    "We have at our disposition a csv (`./data/train.csv`) that we want to explore, the first step is to know what data does our csv contains?\n",
    "\n",
    "**Tasks:**\n",
    "* Using pandas, open `./data/train.csv`\n",
    "* Find what columns our csv contains (name, type and number of values)\n",
    "* Find what is our dataframe's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a5150-2be6-44cd-9e11-b27aaab8931a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be1b1ca8-0856-456b-8ce9-c9a129aa98dc",
   "metadata": {},
   "source": [
    "### I-II Set indexes\n",
    "\n",
    "Nice! We now have a better understanding of our data. It seems like we are facing the `spaceship titanic` dataset, referencing each passager who were on board of the spaceship titanic.\\\n",
    "Our goal is to explore this dataset and finally to create a simple machine learning model to predict if a passenger survived using its informations.\n",
    "\n",
    "To give you a better understanding of our data, here is a description of each columns :\n",
    "* **PassengerId** : ID of the passenger.\n",
    "* **HomePlanet**: Planet of the passenger departed from.\n",
    "* **CryoSleep**: Animation suspended for the duration of the trip.\n",
    "* **Cabin**: Cabin number of passenger.\n",
    "* **Destination**: The planet the passenger will be debarking to.\n",
    "* **Age**: The age of passenger.\n",
    "* **VIP**: Passenger paid for special VIP service.\n",
    "* **RoomService / FoodCourt / ShoppingMall / Spa / VRDeck**: Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "* **Name**: The first and last names of the passenger.\n",
    "* **Transported**: Passenger transported to another dimension.\n",
    "\n",
    "Using the above informations, we can see that the `PassengerId` colomn is just full of indexes referencing each passagenrs.\\\n",
    "Before going futher let's precise that we will use the `PassengerId` column as index.\n",
    "\n",
    "**Tasks:**\n",
    "* Set the DataFrame index using `PassengerId` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da0d3f-0065-48ec-8528-fcded561b720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a8e3542-f6e4-4246-8a40-3dfdbf507cef",
   "metadata": {},
   "source": [
    "Good! Now we can start.\n",
    "\n",
    "### I-III Cleaning dataset\n",
    "\n",
    "One of the main issues in Data Science are missing values. Watch the informations taht you have it your columns and ask yourself which column could be a problem and we should drop.\n",
    "If you said `Cabin` you are right! (IF you said `Age`, remember what does our final goal is in this subject).\n",
    "\n",
    "(In reality we have techniques to deal with missing values but to simplify this subject we will not see them.)\n",
    "\n",
    "Indeed, the `Caibn` column miss soo many values that it useless, we prefer to drop it.\\\n",
    "We can also see that it miss values in the columns `Age` and `HomePlanet`, to simplify the next steps we also decide to drop every row containing missing value(s).\n",
    "\n",
    "**Tasks:**\n",
    "* Drop the `Cabin` column\n",
    "* Drop every rows with one or more missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aada117-18c1-4d4c-8e5e-13b8db5e6a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9aa95aa5-8de0-4c84-b2ab-ac90c4e63811",
   "metadata": {},
   "source": [
    "### I-IV Basic data exploration\n",
    "\n",
    "Now we are sure we no longer have missing values we can go futher.\n",
    "\n",
    "As we can see, our csv contains num√©rics and alphanumerics values. Both are explorable but to start we will focus only on the numerics values.\\\n",
    "A good start would be to know the distribution of each values.\n",
    "\n",
    "**Tasks:**\n",
    "* Find the mean value for each numerical column\n",
    "* Find the std value for each numerical column\n",
    "* Find the min value for each numerical column\n",
    "* Find the lower percentile (25) for each numerical column\n",
    "* Find the median for each numerical column\n",
    "* Find the upper percentile (75) for each numerical column\n",
    "* Find the max value for each numerical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab831788-a4f1-444c-8a56-fb85d388a459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fd3e0ba-c6c8-42ac-a3eb-ce857619867a",
   "metadata": {},
   "source": [
    "We are starting to see a little more clearly, what can we interpret from these data?\n",
    "\n",
    "We can see that an average passenger aboard the spaceship titanic has 30 yrs old\n",
    "On the other hand, we do not learn much more about the `VIP` column.\n",
    "\n",
    "Let's continue to learn about the passengers aboard the Titanic by looking at the number of passengers in VIP class.\n",
    "\n",
    "**Tasks:**\n",
    "* Find how many passengers was in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00baa52d-25fa-4010-bb00-2a31019a2d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eac5db26-ab3e-4fdc-8669-3a0a1247fcbd",
   "metadata": {},
   "source": [
    "We can see that the third class represents almost half of the passengers, it changes our vision of the Titanic ... \\\n",
    "Let's explore a bit the profile of a passenger in each of the classes do you want?\n",
    "\n",
    "**Tasks:**\n",
    "* Find the mean value of the `RoomService` column for each class.\n",
    "* Find the mean value of the `FoodCourt` column for each class.\n",
    "* Display the average age of a passenger in each class\n",
    "* Display the price spent on purchases for each class\n",
    "* Display the rate of transportation in another dimension of passengers in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99868554-a592-414f-828a-7fb6a4bdc844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5475679c-75c9-4455-a2b5-f90b391f6867",
   "metadata": {},
   "source": [
    "We can see very interesting information like:\n",
    "* The \"old\" population is more predominantly in VIP class.\n",
    "* The population that spends the most is the VIP class\n",
    "\n",
    "Now let's move on to different embarkation ports, which one do you think was used the most?\n",
    "\n",
    "To help you, here is the spaceship titanic's journey:\n",
    "\n",
    "<img src=\"./img/solarsystem.jpg\" width=\"700px\" />\n",
    "\n",
    "**Task:**\n",
    "* Find how many passengers embarked by each planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe8718-31e7-4294-b62d-1c2eef95c51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eb31e42-b5ec-4112-ac60-e597f5239ec1",
   "metadata": {},
   "source": [
    "As expected, we can see that on Earth the spaceship Titanic took on the most passengers, followed by Europa its first stop and Mars its second stop.\n",
    "Let's see now how many passengers of each class joined each planet.\n",
    "\n",
    "**Objectif:**\n",
    "* For each class, find how many people embarked on board from which planet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df312f-c4e3-440d-93ce-90e42555bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaafab7a-0e48-4c6f-9ade-4592eb34c207",
   "metadata": {},
   "source": [
    "We notice that for the non VIP classes, the quasi-majority of the passengers embarked on the Earth whereas for the VIP class, a significant proportion of passengers embarked on Europa.\n",
    "\n",
    "### I-V Advance Data Exploration\n",
    "\n",
    "We're starting to see it much more clearly in our data, aren't we? \\\n",
    "Now it's time to explore the correlations between our different values and in particular the transport rate.\n",
    "\n",
    "So start by displaying a simple correlation table between the numerical values.\n",
    "\n",
    "**Task:**\n",
    "* Find and display the correlation between each numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33428b77-4151-4cc9-8ec6-372710f95e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ee6ad8d-9e4d-4c5c-8718-315829c79e8b",
   "metadata": {},
   "source": [
    "We can already interpret a lot of information but before taking a look I suggest that we add some colors.\n",
    "\n",
    "**Task:**\n",
    "* Display a heatmap showing the correlation between each numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf5d15-0fa6-43c2-9d8c-726d2200487d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca110ae4-694f-4b4f-a066-902b3e2dcf9f",
   "metadata": {},
   "source": [
    "Isn't it more pleasant to read? Depending on whether a passenger was carried or not, what can we interpret from this graph?\n",
    "\n",
    "We can see that the class of the passenger was a factor that had a great influence on the passenger's carriage rate.\n",
    "We can see a semblance of correlation between age and whether a passenger was carried, let's try to find out more.\n",
    "\n",
    "**Taks:**\n",
    "* Show the relationship between age and whether or not a passenger was carried using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c4dc7-6e15-4262-b33f-27ea4ddd76f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1201d745-9f29-4342-8843-b3a943c27cc1",
   "metadata": {},
   "source": [
    "Well, we are sure that there is a correlation between age and being transported. \\\n",
    "You know what you have to do...\n",
    "\n",
    "**Task:**\n",
    "* Show if there is a link between a passenger's Age and whether or not it survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6aa42-7444-455e-98a8-d702484f051d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abac49f8-725b-4b8d-a454-2e9a555643fa",
   "metadata": {},
   "source": [
    "Now that we have explored different correlations, we can prepare our data for our model to interpret;\n",
    "\n",
    "Our model only accepts numerical values, so what do we do about the `Transported` column?\n",
    "We just have to convert it into a numerical value.\n",
    "\n",
    "We will also try to show the correlation between age and the fact that a passenger was transported (we saw that a passenger of five years or less is considered a child).\n",
    "\n",
    "\n",
    "**Tasks:**\n",
    "* Create a new column named `Child` and fill it in (remember, we consider a passenger who is under 6 years old to be a child)\n",
    "* Convert the `Transported`, `VIP` and `HomePlanet` column into a numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b9865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af44d5f-b3be-458c-af02-9918509e8af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1fcdd6-71a7-47c6-845c-7ce4cf82612d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af03bad-659a-4a3e-b24a-5eb8647bd24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90e64155-0d3c-419d-b6cb-20378f293eb5",
   "metadata": {},
   "source": [
    "Our data is ready, before we create the model, let's take one last look at the correlations between our data to help us decide which ones might be useful.\n",
    "\n",
    "**Objectives:**\n",
    "* Using a heatmap, show the correlation between all the numerical columns.\n",
    "* Using the `groupby` method of pandas, show the relationship between `Age` and `Transported`.\n",
    "* Using the `groupby` method of pandas, show the relationship between `Child` and `Transported`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d44df-ed9f-42c3-85ce-44b4fc7b634c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd225a55-b0a5-44a1-9af6-67d45ef9504d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54836f7a-a7f2-4947-941b-7cd4f8f27fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "465e79cf-1f3c-43c1-bf28-7d0d2d968671",
   "metadata": {},
   "source": [
    "## II - Machine learning\n",
    "\n",
    "So far we have taken the time to :\n",
    "* Explore the data\n",
    "* View the data\n",
    "* Correlate the data\n",
    "* Interpret the data\n",
    "It's a good start, don't you think?\n",
    "\n",
    "Now let's get down to business (_add a drumbeat_): machine learning (\"_tin tin tin _\").\\\n",
    "For now we're not going to go into too much detail on how to create our models ourselves, we'll just use the `sklearn` library which will do most of the work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082b255-7e06-44c9-b376-25f7b4608711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d43fa7-e602-44e1-9a18-54c21b30bb8f",
   "metadata": {},
   "source": [
    "### II-I Data\n",
    "\n",
    "Before creating our model (promised this is the last step of preparation) we must create a testing and training set (\"_Set what?_\" Said a student in the distance).\\\n",
    "To understand what a test set is and why it is necessary it is best to go over what machine learning is so let's start with a short definition.\n",
    "\n",
    "<ins>Machine learning</ins>: Machine learning is the study of computer algorithms that can improve automatically through experience and by the use of data. It is seen as a part of artificial intelligence.\n",
    "\n",
    "There are two things to remember from this definition:\n",
    "- \"_computer algorithms that can improve automatically_\": In machine learning, we do not directly create the solution but an algorithm that will adjust \"automatically\" until potentially reaching the desired result.\n",
    "- \"_can improve automatically through experience and by the use of data._\": Our model learns thanks to data, so the model is not at the center of our attention, it is first and foremost our data that is.\n",
    "\n",
    "A machine learning model will adjust to meet a single criterion: Bringing the _cost_ closer to zero.\\\n",
    "As a reminder, the loss function (producing the loss) is a function which from a prediction and labels indicates how wrong the model is, the closer the loss is to zero, the better.\n",
    "\n",
    "To illustrate these remarks, I suggest that we take a look at the cost function nammed MSE (mean squared error).\\\n",
    "<img src=\"https://www.gstatic.com/education/formulas2/355397047/en/mean_squared_error.svg\"/>\n",
    "\n",
    "We have here named $Y_i$ the model prediction for a numbered data item $i$ and $\\hat{Y}_i$ the result expected by our model for this same numbered data $i$.\\\n",
    "We sum the results obtained for each data numbered from $0$ to $n$ and take the average of this sum by dividing the result by $n$.\n",
    "\n",
    "We thus obtained the average difference between the predictions of the model and the expected results, it is our cost.\n",
    "\n",
    "The loss is practical to verify the learning of a model, it suffices to verify that the cost decreases as the model learn. On the other hand, if I show you a cost of $100$, it's hard to know if it's good or not, that's where the accuracy comes in, it's the percentage of times the model has found the right result.\\\n",
    "An accuracy of $50%$ would mean that our model is wrong every other time, $90%$ once in 10, etc ...\n",
    "\n",
    "On the other hand, we cannot always have an accurary, take for example a model which aims to predict the exact speed of a car.\\\n",
    "He predicted $121.5km/h$ and the car was going at $119km/h$, you can't tell your model is \"right\" or \"wrong\". You will say rather that it was wrong of $2.5km/h$ (which is a loss).\n",
    "\n",
    "\n",
    "\"_And our history of testing and training set, is where in there? _\" Exclaims the impatient.\\\n",
    "If we summarize, our model learns on the data we give it and tries to reduce the cost calculated according to the prediction of our model and the expected results but if we want to know how our model behaves on the data that it does not have ever seen how we do it? We create a test set, a set of data our model had never see and test it on it ...\n",
    "\n",
    "Our training set is the data that is used by our model to train, our test set is a data that our model has never seen that we use to know how behaves on a data that he has not seen before.\n",
    "To be precise there is even a third set called the validation set but we will not discuss it for the moment.\n",
    "\n",
    "Here as we do not have only one csv, we will have to divide it into two sets (training and testing). \\\n",
    "You understood everything? Perfect! Enough of an explanation like that, let's take action!\n",
    "\n",
    "**Tasks:**\n",
    "* Create a dataframe named `train_df` containing 80% of our data\n",
    "* Create a dataframe named `test_df` containing 20% of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454af9ba-1e1c-4b07-97e4-e563320d31ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0316344d-8d1c-4008-b1d6-2a8705cca78c",
   "metadata": {},
   "source": [
    "Now that we have our sets, it is time to choose the data we will use to train our model.\n",
    "To begin with, we recommend using the columns `VIP`, `Age` and `Child` but you are free to change this selection.\n",
    "\n",
    "**Task:**\n",
    "* Select the columns that you think will be useful in predicting whether a passenger has been transported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fdd221-28d7-407e-a36e-2013905e8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['TODO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77746d1a-51e7-44db-bc40-7ad962ef11a6",
   "metadata": {},
   "source": [
    "We will **FINALLY** be able to switch to buzz word, the machine learning application.\n",
    "\n",
    "To start our first prediction we will use an extremely simple model that some of you may have already seen or used: linear regression.\\\n",
    "The principle of a linear regression is to draw a line in $N$ dimensions where $N$ represents the number of values that we give to our model.\n",
    "\n",
    "To illustrate these words, here is the course of learning a linear regression on a two-dimensional data which is linear: \\\n",
    "![LiRegURL](https://miro.medium.com/max/700/1*CjTBNFUEI_IokEOXJ00zKw.gif \"Linear regression\")\n",
    "\n",
    "This algorithm is quick and easy to set up but only works if the data is linear (which answers the equation $y = b_0 + b_1x$).\\\n",
    "Is ours? Let's try and we'll see.\n",
    "\n",
    "**Task:**\n",
    "* Train a linear regression model on your training set and test it on your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb2ff7-1335-4b81-a6e1-0e47d85682e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59b97acf-a496-4a53-9e7b-3c951acae5f8",
   "metadata": {},
   "source": [
    "If you have inconclusive results (less than $0.23$) don't be surprised.\\\n",
    "Obviously our data is not linear (not surprisingly), you can check by executing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5cf2c6-8fbe-4248-b594-1825131ec056",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(file.Age, file.Transported)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2958811-3809-4276-aedd-0a7b0b0a38f4",
   "metadata": {},
   "source": [
    "An algorithm that might be more promising is logisitic regression, it tries to apply the following formula:\n",
    "## $\\frac{1}{(1 + e^{-(b_0 + b_1x)}}$\n",
    "\n",
    "Let's see what it looks like!\n",
    "\n",
    "**Task:**\n",
    "* Train a logistic regression model on your training set and test it on your test set and display your score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b8fd3-3f1b-4e4a-b4f9-a28efa6857cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1585e4fa-bbe3-496a-ab6c-43737fc4a390",
   "metadata": {},
   "source": [
    "You should have much better results (over $0.70$).\n",
    "\n",
    "To conclude, let's try another kind of algorithm, a decision tree named Random forest.\\\n",
    "We will not detail its operation here but we urge you more than strongly to inquire about it.\n",
    "\n",
    "**Task:**\n",
    "* Train a Random Forest decision tree on your training set and test it on your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cff69-5df7-4de5-bb88-23370bd3f3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfc516f5-d3dd-47bb-9a79-c8d3e5482905",
   "metadata": {},
   "source": [
    "Congratulations! You have quickly discovered the basics of data science and used your first machine learning models, I am impressed.\n",
    "\n",
    "## III - It's your turn!\n",
    "\n",
    "To conclude this subject, we have a challenge for you. Go to [this website](https://www.kaggle.com/competitions/spaceship-titanic/) and try to solve the challenge.\\\n",
    "The one with the best results will earn **100 points** on the day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff6268-4688-4042-bcf2-6dd47311857c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
